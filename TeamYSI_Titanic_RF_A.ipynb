{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team YSI - Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - number of rows: 891\n",
      "Testing data - number of rows:  418\n",
      "Total data - number of rows:    1309\n",
      "\n",
      "ALL DATA\n",
      "Age                                 22\n",
      "Cabin                              NaN\n",
      "Embarked                             S\n",
      "Fare                              7.25\n",
      "Name           Braund, Mr. Owen Harris\n",
      "Parch                                0\n",
      "PassengerId                          1\n",
      "Pclass                               3\n",
      "Sex                               male\n",
      "SibSp                                1\n",
      "Survived                             0\n",
      "Ticket                       A/5 21171\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Age                                 NaN\n",
      "Cabin                               NaN\n",
      "Embarked                              C\n",
      "Fare                            22.3583\n",
      "Name           Peter, Master. Michael J\n",
      "Parch                                 1\n",
      "PassengerId                        1309\n",
      "Pclass                                3\n",
      "Sex                                male\n",
      "SibSp                                 1\n",
      "Survived                            NaN\n",
      "Ticket                             2668\n",
      "Name: 417, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#\n",
    "# Titanic: Machine Learning from Disaster\n",
    "#\n",
    "# Python script for generation of a model predicting the survivals.\n",
    "#\n",
    "# Amendment date             Amended by            Description\n",
    "# 22/11/2016                 Ivaylo Shalev         Initial version.\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Reading of input data (train and test)\n",
    "main_train_df = pd.read_csv('input/train.csv', header=0)      # Load the train file into a dataframe\n",
    "main_test_df = pd.read_csv('input/test.csv', header=0)        # Load the test file into a dataframe\n",
    "\n",
    "# The test data doesn't contain the target (survived), however it still can be used when we are doing data preparation\n",
    "# That's why we create a third dataframe which will contain both training and test data into one.\n",
    "# When executing the modeling we will split them back.\n",
    "main_all_df = main_train_df.append(main_test_df)              # Create a union between both data frames\n",
    "\n",
    "# Show some stats\n",
    "print \"Training data - number of rows: %s\" % main_train_df['PassengerId'].size\n",
    "print \"Testing data - number of rows:  %s\" % main_test_df['PassengerId'].size\n",
    "print \"Total data - number of rows:    %s\" % main_all_df['PassengerId'].size\n",
    "print \"\"\n",
    "\n",
    "# training data\n",
    "print \"ALL DATA\"\n",
    "# show first row\n",
    "print main_all_df.iloc[0]\n",
    "print \"\"\n",
    "# show last row\n",
    "print main_all_df.iloc[-1]\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# PassengerId - do nothing (as it is - int), but it will not be used as a feature\n",
    "# Pclass - do nothing (as it is - int 1,2,3)\n",
    "# SibSp - do nothing (as it is - int 1,2,3,4,5,6,7,8)\n",
    "# Parch - do nothing (as it is - int 1,2,3,4,5,6,7,8)\n",
    "\n",
    "# Survived - convert to int\n",
    "main_all_df['Survived'] = main_all_df.ix[main_all_df.Survived.isnull() == False, 'Survived'].astype(np.int)\n",
    "\n",
    "# Sex - convert it to ID (int): 0 - female, 1 - male\n",
    "main_all_df['GenderId'] = [ 0 if x == 'female' else 1 for x in main_all_df['Sex'] ]\n",
    "\n",
    "# Cabin - extract Deck letter and convert it to ID (int)\n",
    "main_all_df['DeckId'] = [ 0 if np.isnan(x) else x.astype(int) for x in main_all_df['Cabin'].str[:1].map(\n",
    "        {\n",
    "            'T': 1 # Boat Deck - most top\n",
    "         ,  'A': 2 # higher\n",
    "         ,  'B': 3\n",
    "         ,  'C': 4\n",
    "         ,  'D': 5\n",
    "         ,  'E': 6\n",
    "         ,  'F': 7\n",
    "         ,  'G': 8 # lowest deck\n",
    "        })]\n",
    "\n",
    "\"\"\"\n",
    "Avg Fare per Deck\n",
    "1     35.500000\n",
    "2     41.244314\n",
    "3    122.383078\n",
    "4    107.926598\n",
    "5     53.007339\n",
    "6     54.564634\n",
    "7     18.079367\n",
    "8     14.205000\n",
    "\"\"\"\n",
    "\n",
    "main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 30) & (main_all_df.Fare < 38), 'DeckId'] = 1\n",
    "#main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 37) & (main_all_df.Fare < 45), 'DeckId'] = 2\n",
    "main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 110) & (main_all_df.Fare < 130), 'DeckId'] = 3\n",
    "main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 95) & (main_all_df.Fare < 110), 'DeckId'] = 4\n",
    "main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 52) & (main_all_df.Fare < 60), 'DeckId'] = 5\n",
    "#main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 45) & (main_all_df.Fare < 53), 'DeckId'] = 6\n",
    "main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 15) & (main_all_df.Fare < 25), 'DeckId'] = 7\n",
    "main_all_df.ix[(main_all_df.DeckId == 0) & (main_all_df.Fare > 10) & (main_all_df.Fare < 16), 'DeckId'] = 8\n",
    "#print main_all_df.groupby('DeckId').count()['PassengerId']\n",
    "\n",
    "\n",
    "# Name - extract family name and title\n",
    "# Name - Surname\n",
    "#main_all_df['Surname'] = main_all_df['Name'].replace(\"(\\\\,..*)\", \"\", regex=True)\n",
    "\n",
    "# Name - Title - group common titles and factor them all\n",
    "main_all_df['Title'] = main_all_df['Name'].replace(\"(.*, )|(\\\\..*)\", \"\", regex=True)\n",
    "common_titles = [['Other', 0], [\"Miss\", 1], [\"Mr\", 2], [\"Master\", 3], [\"Mile\", 1], [\"Ms\", 1], [\"Mme\", 2]]\n",
    "common_titles_dict = { title : i for title, i in common_titles }\n",
    "main_all_df['TitleId'] = [ 'Other' if x not in list(common_titles_dict) else x for x in main_all_df['Title'] ]\n",
    "main_all_df['TitleId'] = main_all_df['TitleId'].map( lambda x: common_titles_dict[x])\n",
    "\n",
    "\n",
    "# Embarked - decode letter to ID (int)\n",
    "main_all_df['EmbarkedId'] = [ 0 if np.isnan(x) else x.astype(int) for x in main_all_df['Embarked'].map(\n",
    "        {\n",
    "            'C': 1 # Cherbourg\n",
    "         ,  'Q': 2 # Queenstown\n",
    "         ,  'S': 3 # Southampton\n",
    "        })]\n",
    "\n",
    "# Age - get median per gender and apply for null\n",
    "median_age_f = main_all_df.ix[main_all_df['GenderId'] == 0, 'Age'].dropna().astype(np.float).median()\n",
    "median_age_m = main_all_df.ix[main_all_df['GenderId'] == 1, 'Age'].dropna().astype(np.float).median()\n",
    "main_all_df.ix[(main_all_df['GenderId'] == 0) & (main_all_df['Age'].isnull()), 'Age'] = median_age_f\n",
    "main_all_df.ix[(main_all_df['GenderId'] == 1) & (main_all_df['Age'].isnull()), 'Age'] = median_age_m\n",
    "\n",
    "#print main_all_df.groupby(['Sex', 'DeckId']).median()['Age']\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Age')\n",
    "plt.xlabel('Value')\n",
    "main_all_df.ix[main_all_df.GenderId == 1, 'Age'].fillna(-10).plot.hist(bins=20)\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Family Size - sum SibSp + Parch + 1\n",
    "main_all_df['FamSize'] = main_all_df.SibSp + main_all_df.Parch + 1\n",
    "\n",
    "# Child\n",
    "main_all_df['Child'] = 0\n",
    "main_all_df.loc[main_all_df.Age < 18, 'Child'] = 1\n",
    "\n",
    "# Mother\n",
    "main_all_df['Mother'] = 0\n",
    "main_all_df.loc[  (main_all_df.Age >= 18)\n",
    "                & (main_all_df.Parch > 0)\n",
    "                & (main_all_df.GenderId == 0)\n",
    "                & (main_all_df.Title != \"Miss\"), 'Mother'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Accuracy: 0.83 (+/- 0.06)\n",
      "Predicting...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "\n",
    "# Split into Train and Test DF\n",
    "# get only the good features, ID and Target\n",
    "all_good_df = main_all_df[[\n",
    "     'PassengerId'\n",
    "    ,'Survived'\n",
    "    ,'TitleId'\n",
    "    ,'GenderId'\n",
    "    ,'DeckId'\n",
    "    ,'EmbarkedId'\n",
    "    ,'Pclass'\n",
    "    #,'FamSize'\n",
    "    #,'Child'\n",
    "    #,'Mother'\n",
    "    #,'Age'\n",
    "    #,'Fare'\n",
    "    #,'SibSp'\n",
    "    #,'Parch'\n",
    "]]\n",
    "\n",
    "# Split rows into original sets\n",
    "train_df = all_good_df.ix[all_good_df.PassengerId <= 891]\n",
    "test_df = all_good_df.ix[all_good_df.PassengerId > 891]\n",
    "\n",
    "# Get ID and Target\n",
    "test_ids = test_df['PassengerId'].values\n",
    "target_df = all_good_df.ix[all_good_df.PassengerId <= 891, 'Survived']\n",
    "\n",
    "# Remove ID and Target columns from the datasets\n",
    "train_df = train_df.drop(['PassengerId', 'Survived'], axis = 1)\n",
    "test_df = test_df.drop(['PassengerId', 'Survived'], axis = 1)\n",
    "\n",
    "# RandomForest\n",
    "print 'Training...'\n",
    "forest_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Cross validation\n",
    "scores = cross_validation.cross_val_score(forest_model\n",
    "                                          ,train_df\n",
    "                                          ,target_df\n",
    "                                          ,cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n",
    "# Predict\n",
    "print 'Predicting...'\n",
    "forest_model = forest_model.fit(train_df, target_df)\n",
    "predict_output = forest_model.predict(test_df).astype(int)\n",
    "results_df = pd.DataFrame({'PassengerId': test_ids, 'Survived': predict_output})\n",
    "# Save to CSV file\n",
    "results_df.to_csv(path_or_buf=\"output/ysi_titanic_prediction.csv\", index=False)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
